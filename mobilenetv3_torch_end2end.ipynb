{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bda499f",
   "metadata": {},
   "source": [
    "# PyTorch MobileNetV3-Small — End-to-End (Fast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46b4aca",
   "metadata": {},
   "source": [
    "# Sea Animals Image Classification — End-to-End\n",
    "This notebook runs **split → train → evaluate → predict** for one algorithm.\n",
    "**Expected folder on your machine** (run this notebook from your project root):\n",
    "\n",
    "```\n",
    "Sea-Animals-Image-DatasetProject/\n",
    "├── Sea Animals Image Dataset/   # raw classes folders\n",
    "├── FishDataset/                 # will be created (train/val)\n",
    "└── models/                      # will be created (artifacts)\n",
    "```\n",
    "\n",
    "> If your raw dataset folder is named differently (e.g., `Sea_Animals_Image_Dataset`), edit the `DATASET_CANDIDATE_NAMES` list in the split cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3033f3",
   "metadata": {},
   "source": [
    "## 0) Optional installs (run if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8456c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## !pip install torch torchvision matplotlib scikit-learn pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876ae034",
   "metadata": {},
   "source": [
    "## 1) Setup paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28c1463f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: f:\\Git\\Sea Animals Image DatasetProject\n",
      "Raw dataset : f:\\Git\\Sea Animals Image DatasetProject\\Sea Animals Image Dataset\n",
      "FishDataset : f:\\Git\\Sea Animals Image DatasetProject\\FishDataset\n",
      "Models dir  : f:\\Git\\Sea Animals Image DatasetProject\\models\n"
     ]
    }
   ],
   "source": [
    "# Paths and basic setup\n",
    "from pathlib import Path\n",
    "import os, shutil, random, time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "RAW_DIR = None\n",
    "DATASET_CANDIDATE_NAMES = [\n",
    "    \"Sea Animals Image Dataset\",\n",
    "    \"Sea_Animals_Image_Dataset\",\n",
    "    \"SeaAnimalsImageDataset\",\n",
    "]\n",
    "\n",
    "for name in DATASET_CANDIDATE_NAMES:\n",
    "    cand = ROOT / name\n",
    "    if cand.exists() and cand.is_dir():\n",
    "        RAW_DIR = cand\n",
    "        break\n",
    "\n",
    "if RAW_DIR is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Raw dataset folder not found. Create a folder named one of: \"\n",
    "        + \", \".join(DATASET_CANDIDATE_NAMES)\n",
    "        + \" inside your project root.\"\n",
    "    )\n",
    "\n",
    "FISHDATASET = ROOT / \"FishDataset\"\n",
    "TRAIN_DIR = FISHDATASET / \"train\"\n",
    "VAL_DIR = FISHDATASET / \"val\"\n",
    "MODELS_DIR = ROOT / \"models\"\n",
    "MODELS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"Project root:\", ROOT)\n",
    "print(\"Raw dataset :\", RAW_DIR)\n",
    "print(\"FishDataset :\", FISHDATASET)\n",
    "print(\"Models dir  :\", MODELS_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc7f677",
   "metadata": {},
   "source": [
    "## 2) Split dataset (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75717e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Clams: 397 train / 100 val\n",
      "Class Corals: 400 train / 100 val\n",
      "Class Crabs: 399 train / 100 val\n",
      "Class Dolphin: 625 train / 157 val\n",
      "Class Eel: 397 train / 100 val\n",
      "Class Fish: 395 train / 99 val\n",
      "Class Jelly Fish: 676 train / 169 val\n",
      "Class Lobster: 399 train / 100 val\n",
      "Class Nudibranchs: 400 train / 100 val\n",
      "Class Octopus: 449 train / 113 val\n",
      "Class Otter: 400 train / 100 val\n",
      "Class Penguin: 385 train / 97 val\n",
      "Class Puffers: 424 train / 107 val\n",
      "Class Sea Rays: 413 train / 104 val\n",
      "Class Sea Urchins: 463 train / 116 val\n",
      "Class Seahorse: 382 train / 96 val\n",
      "Class Seal: 331 train / 83 val\n",
      "Class Sharks: 472 train / 118 val\n",
      "Class Shrimp: 390 train / 98 val\n",
      "Class Squid: 386 train / 97 val\n",
      "Class Starfish: 399 train / 100 val\n",
      "Class Turtle_Tortoise: 216 train / 55 val\n",
      "✅ Split done → FishDataset/train & FishDataset/val\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Clams', 397, 100),\n",
       " ('Corals', 400, 100),\n",
       " ('Crabs', 399, 100),\n",
       " ('Dolphin', 625, 157),\n",
       " ('Eel', 397, 100),\n",
       " ('Fish', 395, 99),\n",
       " ('Jelly Fish', 676, 169),\n",
       " ('Lobster', 399, 100),\n",
       " ('Nudibranchs', 400, 100),\n",
       " ('Octopus', 449, 113),\n",
       " ('Otter', 400, 100),\n",
       " ('Penguin', 385, 97),\n",
       " ('Puffers', 424, 107),\n",
       " ('Sea Rays', 413, 104),\n",
       " ('Sea Urchins', 463, 116),\n",
       " ('Seahorse', 382, 96),\n",
       " ('Seal', 331, 83),\n",
       " ('Sharks', 472, 118),\n",
       " ('Shrimp', 390, 98),\n",
       " ('Squid', 386, 97),\n",
       " ('Starfish', 399, 100),\n",
       " ('Turtle_Tortoise', 216, 55)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split raw dataset into train/val (80/20) — idempotent\n",
    "import os, shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TRAIN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "VAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "classes = [d for d in RAW_DIR.iterdir() if d.is_dir()]\n",
    "if not classes:\n",
    "    raise RuntimeError(f\"No class folders found under {RAW_DIR}\")\n",
    "\n",
    "count_summary = []\n",
    "for cls_path in classes:\n",
    "    cls = cls_path.name\n",
    "    images = [p for p in cls_path.iterdir() if p.suffix.lower() in {\".jpg\",\".jpeg\",\".png\"}]\n",
    "    if not images:\n",
    "        print(\"Skip (no images):\", cls)\n",
    "        continue\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train, val = train_test_split(images, test_size=0.2, random_state=42)\n",
    "    (TRAIN_DIR/cls).mkdir(parents=True, exist_ok=True)\n",
    "    (VAL_DIR/cls).mkdir(parents=True, exist_ok=True)\n",
    "    for src in train:\n",
    "        dst = TRAIN_DIR/cls/src.name\n",
    "        if not dst.exists():\n",
    "            shutil.copy2(src, dst)\n",
    "    for src in val:\n",
    "        dst = VAL_DIR/cls/src.name\n",
    "        if not dst.exists():\n",
    "            shutil.copy2(src, dst)\n",
    "    count_summary.append((cls, len(train), len(val)))\n",
    "    print(f\"Class {cls}: {len(train)} train / {len(val)} val\")\n",
    "\n",
    "print(\"✅ Split done → FishDataset/train & FishDataset/val\")\n",
    "count_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0018f644",
   "metadata": {},
   "source": [
    "## 3) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d28d91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to C:\\Users\\FURY/.cache\\torch\\hub\\checkpoints\\mobilenet_v3_small-047dcff4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8 → Train=36.84% | Val=54.35%\n"
     ]
    }
   ],
   "source": [
    "# Train MobileNetV3-Small\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "print(\"Device:\", device)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=transform_train)\n",
    "val_dataset   = datasets.ImageFolder(VAL_DIR,   transform=transform_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=64, shuffle=False)\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "model = models.mobilenet_v3_small(weights=\"IMAGENET1K_V1\")\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=2e-4)\n",
    "\n",
    "EPOCHS = 8\n",
    "train_acc, val_acc = [], []\n",
    "best = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    correct, total = 0, 0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels).sum().item()\n",
    "    tr = 100*correct/total\n",
    "    train_acc.append(tr)\n",
    "\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (pred == labels).sum().item()\n",
    "    va = 100*correct/total\n",
    "    val_acc.append(va)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} → Train={tr:.2f}% | Val={va:.2f}%\")\n",
    "    if va > best:\n",
    "        best = va\n",
    "        torch.save(model.state_dict(), MODELS_DIR / \"mobilenetv3_best.pth\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_acc, label=\"Train\")\n",
    "plt.plot(val_acc, label=\"Val\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(MODELS_DIR / \"mobilenetv3_accuracy.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Best Val Acc:\", best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258cfd3f",
   "metadata": {},
   "source": [
    "## 4) Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bc8dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict — MobileNetV3\n",
    "import torch, random\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "classes = [d.name for d in VAL_DIR.iterdir() if d.is_dir()]\n",
    "num_classes = len(classes)\n",
    "\n",
    "model = models.mobilenet_v3_small(weights=None)\n",
    "model.classifier[-1] = torch.nn.Linear(model.classifier[-1].in_features, num_classes)\n",
    "model.load_state_dict(torch.load(MODELS_DIR / \"mobilenetv3_best.pth\", map_location=device))\n",
    "model.eval().to(device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "sample = random.choice(list(VAL_DIR.glob(\"*/*.jpg\")))\n",
    "img = Image.open(sample).convert(\"RGB\")\n",
    "x = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(x)\n",
    "    probs = torch.nn.functional.softmax(logits, dim=1)[0]\n",
    "    idx = int(torch.argmax(probs))\n",
    "    conf = float(probs[idx])*100\n",
    "label = classes[idx]\n",
    "\n",
    "print(f\"✅ Prediction: {label} ({conf:.2f}%) — {sample}\")\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"{label} ({conf:.2f}%)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
