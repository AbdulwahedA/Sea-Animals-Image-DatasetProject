{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78e673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 22:25:35,662 - INFO - üìò Training gestartet\n",
      "2025-11-06 22:25:35,669 - INFO - üî• Device aktiv: cpu\n",
      "2025-11-06 22:25:35,745 - INFO - üìä 22 Klassen erkannt: ['Clams', 'Corals', 'Crabs', 'Dolphin', 'Eel', 'Fish', 'Jelly Fish', 'Lobster', 'Nudibranchs', 'Octopus', 'Otter', 'Penguin', 'Puffers', 'Sea Rays', 'Sea Urchins', 'Seahorse', 'Seal', 'Sharks', 'Shrimp', 'Squid', 'Starfish', 'Turtle_Tortoise']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to C:\\Users\\FURY/.cache\\torch\\hub\\checkpoints\\vit_b_16-c867db91.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# üìò Sea Animals Image Classification (Vision Transformer)\n",
    "# ==========================================\n",
    "# Vollautomatisches Training + Evaluation + Prediction\n",
    "# Erstellt f√ºr Amr Selck\n",
    "# ==========================================\n",
    "\n",
    "# ‚úÖ Falls n√∂tig, Bibliotheken installieren:\n",
    "# !pip install torch torchvision matplotlib scikit-learn pillow\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# ==========================================\n",
    "# 1Ô∏è‚É£ Setup & Logging\n",
    "# ==========================================\n",
    "ROOT = Path().resolve()\n",
    "TRAIN_DIR = ROOT / \"FishDataset/train\"\n",
    "VAL_DIR = ROOT / \"FishDataset/val\"\n",
    "MODELS_DIR = ROOT / \"models\"\n",
    "LOGS_DIR = ROOT / \"logs\"\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "LOGS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "log_file = LOGS_DIR / f\"vit_train_{timestamp}.log\"\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.FileHandler(log_file, encoding=\"utf-8\"), logging.StreamHandler()],\n",
    ")\n",
    "logger = logging.getLogger(\"vit_notebook\")\n",
    "logger.info(\"üìò Training gestartet\")\n",
    "\n",
    "# ==========================================\n",
    "# 2Ô∏è‚É£ Device Detection\n",
    "# ==========================================\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else\n",
    "    \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")\n",
    "logger.info(f\"üî• Device aktiv: {device}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3Ô∏è‚É£ Dataset & Transform\n",
    "# ==========================================\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=transform_train)\n",
    "val_dataset = datasets.ImageFolder(VAL_DIR, transform=transform_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "classes = train_dataset.classes\n",
    "num_classes = len(classes)\n",
    "logger.info(f\"üìä {num_classes} Klassen erkannt: {classes}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4Ô∏è‚É£ Modell (Vision Transformer)\n",
    "# ==========================================\n",
    "model = models.vit_b_16(weights=\"IMAGENET1K_V1\")\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "model.heads = nn.Sequential(\n",
    "    nn.Linear(model.heads.head.in_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, num_classes)\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.heads.parameters(), lr=3e-4)\n",
    "\n",
    "# ==========================================\n",
    "# 5Ô∏è‚É£ Training\n",
    "# ==========================================\n",
    "EPOCHS = 8\n",
    "train_acc, val_acc, val_loss_list = [], [], []\n",
    "best_acc = 0.0\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    correct, total = 0, 0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    train_accuracy = 100 * correct / total\n",
    "    train_acc.append(train_accuracy)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct, total, val_loss = 0, 0, 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc.append(val_accuracy)\n",
    "    val_loss_list.append(val_loss)\n",
    "\n",
    "    logger.info(f\"Epoch {epoch+1}: Train={train_accuracy:.2f}% | Val={val_accuracy:.2f}% | Loss={val_loss:.4f}\")\n",
    "\n",
    "    if val_accuracy > best_acc:\n",
    "        best_acc = val_accuracy\n",
    "        torch.save(model.state_dict(), MODELS_DIR / \"vit_best.pth\")\n",
    "\n",
    "# ==========================================\n",
    "# 6Ô∏è‚É£ Evaluation\n",
    "# ==========================================\n",
    "duration = (time.time() - start_time) / 60\n",
    "logger.info(f\"‚úÖ Training abgeschlossen in {duration:.1f} Min. Beste Val-Acc: {best_acc:.2f}%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "disp.plot(xticks_rotation=\"vertical\", cmap=\"viridis\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODELS_DIR / \"vit_confusion_matrix.png\")\n",
    "plt.close()\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(train_acc, label=\"Train Acc\")\n",
    "plt.plot(val_acc, label=\"Val Acc\")\n",
    "plt.legend()\n",
    "plt.title(\"ViT Accuracy Verlauf\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.grid(True)\n",
    "plt.savefig(MODELS_DIR / \"vit_accuracy.png\")\n",
    "plt.close()\n",
    "\n",
    "# Loss Plot\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(val_loss_list, label=\"Validation Loss\", color=\"orange\")\n",
    "plt.legend()\n",
    "plt.title(\"ViT Loss Verlauf\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.savefig(MODELS_DIR / \"vit_loss.png\")\n",
    "plt.close()\n",
    "\n",
    "logger.info(\"üìà Visualisierungen gespeichert in /models/\")\n",
    "print(\"Training abgeschlossen ‚úÖ\")\n",
    "\n",
    "# ==========================================\n",
    "# 7Ô∏è‚É£ Prediction (Einzelbild-Test)\n",
    "# ==========================================\n",
    "# Lade das gespeicherte Modell\n",
    "model.load_state_dict(torch.load(MODELS_DIR / \"vit_best.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# W√§hle zuf√§lliges Bild aus Validation-Ordner\n",
    "sample = random.choice(list(VAL_DIR.glob(\"*/*.jpg\")))\n",
    "img = Image.open(sample).convert(\"RGB\")\n",
    "\n",
    "# Vorbereitung f√ºr Prediction\n",
    "transform_pred = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "x = transform_pred(img).unsqueeze(0).to(device)\n",
    "\n",
    "# Vorhersage\n",
    "with torch.no_grad():\n",
    "    preds = model(x)\n",
    "    probs = torch.nn.functional.softmax(preds, dim=1)\n",
    "    pred = probs.argmax(dim=1).item()\n",
    "    conf = probs[0][pred].item() * 100\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "plt.imshow(np.array(img))\n",
    "plt.title(f\"‚úÖ Ergebnis: {classes[pred]} ({conf:.2f}% Konfidenz)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "logger.info(f\"üîç Bild: {sample}\")\n",
    "logger.info(f\"‚úÖ Ergebnis: {classes[pred]} ({conf:.2f}% Konfidenz)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20df4f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# üìò Sea Animals Image Classification (Vision Transformer)\n",
    "# ==========================================\n",
    "# Vollautomatisches Training + Evaluation + Prediction\n",
    "# Erstellt f√ºr Amr Selck\n",
    "# ==========================================\n",
    "\n",
    "# ‚úÖ Falls n√∂tig, Bibliotheken installieren:\n",
    "# !pip install torch torchvision matplotlib scikit-learn pillow\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# ==========================================\n",
    "# 1Ô∏è‚É£ Setup & Logging\n",
    "# ==========================================\n",
    "ROOT = Path().resolve()\n",
    "TRAIN_DIR = ROOT / \"FishDataset/train\"\n",
    "VAL_DIR = ROOT / \"FishDataset/val\"\n",
    "MODELS_DIR = ROOT / \"models\"\n",
    "LOGS_DIR = ROOT / \"logs\"\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "LOGS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "log_file = LOGS_DIR / f\"vit_train_{timestamp}.log\"\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.FileHandler(log_file, encoding=\"utf-8\"), logging.StreamHandler()],\n",
    ")\n",
    "logger = logging.getLogger(\"vit_notebook\")\n",
    "logger.info(\"üìò Training gestartet\")\n",
    "\n",
    "# ==========================================\n",
    "# 2Ô∏è‚É£ Device Detection\n",
    "# ==========================================\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else\n",
    "    \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")\n",
    "logger.info(f\"üî• Device aktiv: {device}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3Ô∏è‚É£ Dataset & Transform\n",
    "# ==========================================\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=transform_train)\n",
    "val_dataset = datasets.ImageFolder(VAL_DIR, transform=transform_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "classes = train_dataset.classes\n",
    "num_classes = len(classes)\n",
    "logger.info(f\"üìä {num_classes} Klassen erkannt: {classes}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4Ô∏è‚É£ Modell (Vision Transformer)\n",
    "# ==========================================\n",
    "model = models.vit_b_16(weights=\"IMAGENET1K_V1\")\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "model.heads = nn.Sequential(\n",
    "    nn.Linear(model.heads.head.in_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, num_classes)\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.heads.parameters(), lr=3e-4)\n",
    "\n",
    "# ==========================================\n",
    "# 5Ô∏è‚É£ Training\n",
    "# ==========================================\n",
    "EPOCHS = 8\n",
    "train_acc, val_acc, val_loss_list = [], [], []\n",
    "best_acc = 0.0\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    correct, total = 0, 0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    train_accuracy = 100 * correct / total\n",
    "    train_acc.append(train_accuracy)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct, total, val_loss = 0, 0, 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc.append(val_accuracy)\n",
    "    val_loss_list.append(val_loss)\n",
    "\n",
    "    logger.info(f\"Epoch {epoch+1}: Train={train_accuracy:.2f}% | Val={val_accuracy:.2f}% | Loss={val_loss:.4f}\")\n",
    "\n",
    "    if val_accuracy > best_acc:\n",
    "        best_acc = val_accuracy\n",
    "        torch.save(model.state_dict(), MODELS_DIR / \"vit_best.pth\")\n",
    "\n",
    "# ==========================================\n",
    "# 6Ô∏è‚É£ Evaluation\n",
    "# ==========================================\n",
    "duration = (time.time() - start_time) / 60\n",
    "logger.info(f\"‚úÖ Training abgeschlossen in {duration:.1f} Min. Beste Val-Acc: {best_acc:.2f}%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "disp.plot(xticks_rotation=\"vertical\", cmap=\"viridis\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODELS_DIR / \"vit_confusion_matrix.png\")\n",
    "plt.close()\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(train_acc, label=\"Train Acc\")\n",
    "plt.plot(val_acc, label=\"Val Acc\")\n",
    "plt.legend()\n",
    "plt.title(\"ViT Accuracy Verlauf\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.grid(True)\n",
    "plt.savefig(MODELS_DIR / \"vit_accuracy.png\")\n",
    "plt.close()\n",
    "\n",
    "# Loss Plot\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(val_loss_list, label=\"Validation Loss\", color=\"orange\")\n",
    "plt.legend()\n",
    "plt.title(\"ViT Loss Verlauf\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.savefig(MODELS_DIR / \"vit_loss.png\")\n",
    "plt.close()\n",
    "\n",
    "logger.info(\"üìà Visualisierungen gespeichert in /models/\")\n",
    "print(\"Training abgeschlossen ‚úÖ\")\n",
    "\n",
    "# ==========================================\n",
    "# 7Ô∏è‚É£ Prediction (Einzelbild-Test)\n",
    "# ==========================================\n",
    "# Lade das gespeicherte Modell\n",
    "model.load_state_dict(torch.load(MODELS_DIR / \"vit_best.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# W√§hle zuf√§lliges Bild aus Validation-Ordner\n",
    "sample = random.choice(list(VAL_DIR.glob(\"*/*.jpg\")))\n",
    "img = Image.open(sample).convert(\"RGB\")\n",
    "\n",
    "# Vorbereitung f√ºr Prediction\n",
    "transform_pred = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "x = transform_pred(img).unsqueeze(0).to(device)\n",
    "\n",
    "# Vorhersage\n",
    "with torch.no_grad():\n",
    "    preds = model(x)\n",
    "    probs = torch.nn.functional.softmax(preds, dim=1)\n",
    "    pred = probs.argmax(dim=1).item()\n",
    "    conf = probs[0][pred].item() * 100\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "plt.imshow(np.array(img))\n",
    "plt.title(f\"‚úÖ Ergebnis: {classes[pred]} ({conf:.2f}% Konfidenz)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "logger.info(f\"üîç Bild: {sample}\")\n",
    "logger.info(f\"‚úÖ Ergebnis: {classes[pred]} ({conf:.2f}% Konfidenz)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
